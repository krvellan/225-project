<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Vokse Sites</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div>
        <div class="topnav">
            <a href="index.html">Home</a>
            <a class="active" href="etl-process.html">ETL-Process</a>
            <a href="qr.html">Query/Results</a>
            <a href="Visualizations.html">Visualizations</a>
            <a href="Contributions.html">Contributions</a>
            <a href="References.html">References</a>
        </div>
    </div>
    <div class="section12">
        <h1>ETL-Process</h1>
        <img src="etl.png" width="468.75" height="215.25" class="imgcenter">
        <p1> <br><br>&nbsp;&nbsp;&nbsp;&nbsp; What is the "ETL-Process"? The "ETL-Process" is the process in which data is
            extracted, transformed, and loaded. Extraction is the process in which data is taken from multiple
            different places and put in one place. In our project we took the data from two sources OpenAQ, and the
            NOAA USRCRN weather data. We scrapped the data and loaded the data to S3 buckets. From here we transformed
            the data by extracting data that was only relevant to our project. We went ahead and extracted the data
            for the Santa Barbara, CA area and pulled out columns that we thought would be helpfull for our project.
            We then took the transformed data and loaded it using AWS Glue and redshift (which was used to create the
            tables and query the data). Using the datasets we have also created tables to show the parameters of the
            tables</p1>
    </div>
</body>
</html>